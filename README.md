# Multi-Agent Reinforcement Learning for Adaptive Traffic Signal Control in SUMO

A complete framework for training and evaluating **multi-agent reinforcement learning (MARL)** systems for adaptive traffic signal control in realistic urban environments, using the **SUMO** microscopic traffic simulator.

This repository implements the full system developed in my Bachelor thesis **‚ÄúMulti-Agent Reinforcement Learning for Adaptive Traffic Signal Control in SUMO‚Äù** (2025), including network preprocessing, agent training, evaluation, and reproducible experiments.

## üìã Overview

This project provides an end-to-end pipeline for learning adaptive traffic signal control policies using multi-agent PPO. Key components:

- **Multi-Agent RL Training**  
  Each traffic light (TLS) is controlled by an independent RL agent using PPO (Stable-Baselines3).

- **Real-World Network Integration**  
  Based on an OpenStreetMap (OSM) extract of Karlsruhe, Germany, including 17 signalized intersections.

- **Multiple Reward Functions**  
  Evaluate different policy objectives:
  - waiting time
  - queue length
  - emissions
  - combined real-world metrics

- **Automated Network Processing**  
  Includes several scripts to repair, validate, and clean OSM-imported networks.

- **Comprehensive Evaluation**  
  Systematic benchmarking against fixed-time and actuated baselines.

## üèóÔ∏è Architecture

```
SUMO Simulation ‚Üî TraCI Interface ‚Üî SUMO-RL Environment ‚Üî Stable-Baselines3 (PPO)
                          ‚Üë
                 Multi-Agent Controller
                          ‚Üë
               17 Independent RL Agents
```

## üöÄ Quick Start

### Prerequisites

- Python 3.10+
- SUMO 1.18.0 or newer
- 16GB RAM recommended

### Installation

1. **Install SUMO**
   ```bash
   sudo apt-get install sumo sumo-tools sumo-doc
   ```

2. **Set the SUMO_HOME environment variable**
   ```bash
   export SUMO_HOME="/path/to/sumo"
   ```

3. **Clone this repository and install dependencies**
   ```bash
   git clone https://github.com/zamweis/sumo-marl-traffic-control.git
   cd sumo-marl-traffic-control
   pip install -r requirements.txt
   ```
4.  **Install sumo-rl**

    clone sumo-rl repository and add to path

5. **Implement emissions in sumo-rl**
   
    in sumo_rl/environment/env.py modify  _compute_info(self)
    ```
    def _compute_info(self):
        info = {"step": self.sim_step}
        if self.add_system_info:
            info.update(self._get_system_info())

            # --- NEU: CO‚ÇÇ Emissionen ---
            lanes = []
            for ts in self.traffic_signals.values():
                lanes.extend(ts.lanes)   # <<--- wichtig!
            if lanes:
                total_co2 = sum(self.sumo.lane.getCO2Emission(lane) for lane in lanes)
                n_veh = sum(self.sumo.lane.getLastStepVehicleNumber(lane) for lane in lanes)
                mean_co2 = total_co2 / max(1, n_veh)
                info["system_mean_co2"] = mean_co2

        if self.add_per_agent_info:
            info.update(self._get_per_agent_info())
        self.metrics.append(info.copy())
        return info
     ```

## ‚ñ∂Ô∏è Basic Usage

### **1. Prepare or repair the SUMO network**
Use one of the provided repair scripts:

```bash
python scripts/repair_net.py
python scripts/check_tls_consistency.py
.
.
.
python scripts/find_valid_tls.py
```
Some networks need manual deletion of railway tls.

### **2. Train an RL model**
```bash
python train.py
```

### **3. Continue training a saved model**
```bash
python continuetrain.py
```

### **4. Evaluate trained models**
```bash
python evaluate.py
```

Evaluation results are saved in JSON and CSV format.

## üìÇ Repository Structure

```
sumo-marl-traffic-control/
‚îú‚îÄ‚îÄ scripts/                     # Network processing & SUMO/OSM repair tools
‚îÇ   ‚îú‚îÄ‚îÄ check_tls_consistency.py
‚îÇ   ‚îú‚îÄ‚îÄ fix_requests.py
‚îÇ   ‚îú‚îÄ‚îÄ repair_net.py
‚îÇ   ‚îî‚îÄ‚îÄ find_valid_tls.py
‚îÇ
‚îú‚îÄ‚îÄ latex/                       # Thesis (LaTeX source)
‚îÇ   ‚îî‚îÄ‚îÄ ...                     
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ diffwaitingtime/         # Reward: diff-waiting-time (training + evaluation)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ continuetrain.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/          # Auto-created evaluation outputs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runs/                # Auto-created model checkpoints + logs
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ realworld/               # Reward: real-world metric combination
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ continuetrain.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runs/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ emissions/               # Reward: CO‚ÇÇ emission minimization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ continuetrain.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runs/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ queue/                   # Reward: queue-length reduction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ continuetrain.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ runs/
‚îÇ
‚îú‚îÄ‚îÄ data/                        # SUMO network, traffic flows & config files
‚îÇ   ‚îú‚îÄ‚îÄ map.net.xml
‚îÇ   ‚îú‚îÄ‚îÄ flows_*.rou.xml
‚îÇ   ‚îî‚îÄ‚îÄ sumoconfig.sumocfg
‚îÇ
‚îî‚îÄ‚îÄ runs/ (optional)             # Only used if models are moved here manually
```

## üéØ Key Features

### Reward Functions
- **Diff-Waiting-Time**: Minimize cumulative waiting time difference  
- **Queue**: Minimize the number of stopped vehicles  
- **Real-World**: Weighted combination of speed, queue length, waiting time  
- **Emissions**: Reduce CO‚ÇÇ emissions while maintaining traffic flow  

### Network Processing
- Automated OSM ‚Üí SUMO conversion  
- TLS consistency checking and repair  
- Automatic request index fixing  
- Identification of RL-compatible TLS  
- Validation of lane and edge structures  

### RL Training
- Multi-agent PPO (Stable-Baselines3)  
- Scenario-based curriculum learning  
- TensorBoard logging  
- Periodic checkpoints and best model selection  

## üìö Citation

If you use this repository in your research, please cite:

```
@thesis{weiler2025marl,
  title={Multi-Agent Reinforcement Learning for Adaptive Traffic Signal Control in SUMO},
  author={Weiler, Sam},
  year={2025},
  institution={Hochschule Karlsruhe}
}
```

## ü§ù Contributing

Contributions are welcome!  
Feel free to open issues or submit pull requests.

## üìÑ License

Licensed under the MIT License.  
See the `LICENSE` file for details.

## üôè Acknowledgments

- Prof. Dr. Patrick Baier  
- Prof. Dr. Heiko K√∂rner  
- SUMO development team  
- Lucas Alegre (sumo-rl)  
- Stable-Baselines3 team
